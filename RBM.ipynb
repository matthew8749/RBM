{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%run 'activation.ipynb' \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class RBM:\n",
    "    \n",
    "    def __init__(self, n_v, n_h, W=None, b=None, c=None, k=1):\n",
    "        assert n_v != 0 and n_h != 0\n",
    "        self.n_v = n_v\n",
    "        self.n_h = n_h\n",
    "        shape = (n_h, n_v)\n",
    "        \n",
    "        self.W = W if W is not None else np.random.uniform(-1, 1, size=shape)\n",
    "        self.b = b if b is not None else np.zeros(n_v)\n",
    "        self.c = c if c is not None else np.zeros(n_h)\n",
    "\n",
    "        assert self.W.shape==shape and n_v == len(self.b) and n_h == len(self.c)\n",
    "        \n",
    "        self.k = k\n",
    "        return\n",
    "        \n",
    "    def forward(self, V):\n",
    "        n_sample, n_v = V.shape\n",
    "        \n",
    "        hsignal = np.dot(V, self.W.T) + self.c\n",
    "        assert hsignal.shape == (n_sample, self.n_h)\n",
    "        Hp = sigmoid(hsignal)\n",
    "        \n",
    "        #s = np.random.uniform(0, 1, size=hsignal.shape)\n",
    "        #Hs = (s < Hp) * 1  # same as:\n",
    "        Hs = np.random.binomial(1, Hp, size=Hp.shape)\n",
    "        return Hp, Hs\n",
    "    \n",
    "    def backward(self, H):\n",
    "        n_sample, n_h = H.shape\n",
    "        \n",
    "        vsignal = np.dot(H, self.W) + self.b\n",
    "        assert vsignal.shape == (n_sample, self.n_v)\n",
    "        #print(vsignal)\n",
    "        Vp = sigmoid(vsignal)\n",
    "        \n",
    "        s = np.random.uniform(0, 1, size=vsignal.shape)\n",
    "        Vs = (s < Vp) * 1\n",
    "        return Vp, Vs\n",
    "\n",
    "    def gibbs(self, V):  #return (probability, samples) of visible units\n",
    "        Vs = V\n",
    "        for i in range(self.k):\n",
    "            Hp, Hs = self.forward(Vs)\n",
    "            Vp, Vs = self.backward(Hs)\n",
    "            \n",
    "        return Hp, Hs, Vp, Vs\n",
    "    \n",
    "    def contrastive_divergence(self, V, learning=0.01):\n",
    "        #set_trace()\n",
    "        n_sample, n_v = V.shape\n",
    "        \n",
    "        Vs = V\n",
    "        Hp, Hs, Vp_, Vs_ = self.gibbs(Vs)   # underscore _ refers to tilde for negative sample\n",
    "        Hp_, Hs_ = self.forward(Vs_)\n",
    "\n",
    "        Vs1 = np.mean(Vs, axis=0) \n",
    "        Vs2 = np.mean(Vs_, axis=0) \n",
    "        Hp1 = np.mean(Hp, axis=0)\n",
    "        Hp2 = np.mean(Hp_, axis=0)\n",
    "        Hs1 = np.mean(Hs, axis=0)\n",
    "        Hs2 = np.mean(Hs_, axis=0)\n",
    "        \n",
    "        # note, there are variances in how to compute the gradients.\n",
    "        # Hugo suggests:     h(v1)*v1 - h(v2)*v2\n",
    "        # Bengio suggests:   h1*v1 - h(v2)*v2\n",
    "        # My derivation:     h1(v1)*v1 - h2*v2 \n",
    "        \n",
    "        Eh_b = Vs1; Evh_b = Vs2      # Evh_b refers to the Expectation (over v and h) of -logP(v) gradient wrt b\n",
    "        \n",
    "        #Eh_c = Hs1; Evh_c = Hp2  # bengio\n",
    "        Eh_c = Hp1; Evh_c = Hp2  # hugo\n",
    "        #Eh_c = Hp1; Evh_c = Hs2  # Mine\n",
    "\n",
    "        g_b = Evh_b - Eh_b  # gradient of -logP(v) wrt b\n",
    "        g_c = Evh_c - Eh_c\n",
    "\n",
    "        Eh_W = np.outer(Eh_c, Eh_b) \n",
    "        Evh_W = np.outer(Evh_c, Evh_b)\n",
    "        g_W = Evh_W - Eh_W\n",
    "    \n",
    "        self.W -= g_W * learning\n",
    "        self.b -= g_b * learning\n",
    "        self.c -= g_c * learning        \n",
    "        return\n",
    "    \n",
    "    def reconstruct(self, V):\n",
    "        Hp, Hs = self.forward(V)\n",
    "        Vp, Vs = self.backward(Hp)\n",
    "        return Vp, Vs\n",
    "\n",
    "    def save_model(self, save_file):\n",
    "        dict = {'n_v':self.n_v, 'n_h':self.n_h, 'W':self.W, 'b':self.b, 'c':self.c}\n",
    "        save_file += \".\"+ str(self.n_v) + \"x\" + str(self.n_h)\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, load_file):\n",
    "        with open(load_file, 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "\n",
    "        rbm = cls(m['n_v'], m['n_h'], m['W'], m['b'], m['c'])\n",
    "        return rbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing of the RBM code above\n",
    "\n",
    "%run \"mnist.ipynb\"\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import Grid\n",
    "\n",
    "class MNIST_RBM:\n",
    "\n",
    "    def __init__(self, n_v, n_h, load_file=None, data_path=\"./convolution-network\"):\n",
    "        if load_file is None: \n",
    "            self.rbm = RBM(n_v, n_h)\n",
    "        else:\n",
    "            self.rbm = RBM.load_model(load_file)\n",
    "        \n",
    "        self.train_input = MnistInput(\"train\", data_path)\n",
    "        self.test_input = MnistInput(\"test\", data_path)\n",
    "        self.save_file = \"mnist_rbm\"                  \n",
    "\n",
    "\n",
    "    def train_model(self, train_size=-1, n_epoch=100, batch_size=10, learning=0.01):\n",
    "        n_ep = 0\n",
    "        n_x = 0 \n",
    "        X = []\n",
    "        Y = []\n",
    "        batch_size = batch_size if batch_size > 0 else 100\n",
    "        n_epoch = n_epoch if n_epoch > 0 else 1\n",
    "        for i in range(n_epoch):\n",
    "            for x, y in self.train_input.read(train_size):\n",
    "                n_x += 1\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                if n_x >= batch_size:\n",
    "                    X = np.array(X).reshape(batch_size, -1) > 30\n",
    "                    X = X * 1 # make bool into number\n",
    "                    Y = np.array(Y)  \n",
    "                    self.rbm.contrastive_divergence(X, learning)\n",
    "                    n_x = 0\n",
    "                    X = []\n",
    "                    Y = []       \n",
    "                    \n",
    "        self.save_file = self.save_file + \".epochs\" + str(n_epoch)                   \n",
    "        self.rbm.save_model(self.save_file)\n",
    "        return\n",
    "\n",
    "    def test_reconstruct(self, n):\n",
    "        X=[]; i=0\n",
    "        for x, y in self.test_input.read(n):\n",
    "            x *= np.random.binomial(1, 1-i/(2*n), size=(28,28))\n",
    "            X.append(x)\n",
    "            i += 1\n",
    "\n",
    "        ncols = 10\n",
    "        nrows = int(n/5)\n",
    "        fig = plt.figure(figsize=(ncols, nrows), dpi=300)\n",
    "        grid = Grid(fig, rect=111, nrows_ncols=(nrows,10))\n",
    "\n",
    "        for i, ax in enumerate(grid):\n",
    "            j = i//2\n",
    "            if i%2 == 0:\n",
    "                ax.imshow(X[j].reshape(28,28), cmap=mpl.cm.Greys)\n",
    "                if i<ncols:\n",
    "                    ax.set_title(\"Original\")\n",
    "            else:\n",
    "                Vp, Vs = self.rbm.reconstruct(X[j].reshape(1, -1)/255)\n",
    "                ax.imshow(Vp.reshape(28,28), cmap=mpl.cm.Greys)\n",
    "                if i<ncols:\n",
    "                    ax.set_title(\"Reconst.\")\n",
    "\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        fig.suptitle('Original and reconstructed digits side by side')\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.80)    \n",
    "        plt.show()        \n",
    "        return\n",
    "\n",
    "    def show_features(self):\n",
    "        rbm = self.rbm\n",
    "        maxw = np.amax(rbm.W)\n",
    "        minw = np.amin(rbm.W)\n",
    "        ncols = rbm.n_h if rbm.n_h < 14 else 14 \n",
    "        nrows = int(rbm.n_h/ncols)\n",
    "        fig = plt.figure(figsize=(ncols, nrows), dpi=100)\n",
    "        grid = Grid(fig, rect=111, nrows_ncols=(nrows, ncols), axes_pad=0.01)\n",
    "\n",
    "        for i, ax in enumerate(grid):\n",
    "            x = rbm.W[i]\n",
    "            x = (x.reshape(1, -1) - minw)/maxw\n",
    "            ax.imshow(x.reshape(28,28), cmap=mpl.cm.Greys)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        fig.suptitle('Features learned with RBM from MNIST', size=20)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.85 + nrows*0.002)    \n",
    "        plt.show()\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m mnist_rbm \u001b[39m=\u001b[39m MNIST_RBM(\u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m20\u001b[39m, load_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m mnist_rbm\u001b[39m.\u001b[39mtrain_model(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_epoch\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m rbm\u001b[39m.\u001b[39mshow_features()\n\u001b[1;32m      9\u001b[0m rbm\u001b[39m.\u001b[39mtest_reconstruct(\u001b[39m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rbm' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_rbm = None\n",
    "if __name__ == \"__main__\" and '__file__' not in globals():\n",
    "    \n",
    "    np.seterr(all='raise')\n",
    "    plt.close('all')\n",
    "    mnist_rbm = MNIST_RBM(28*28, 28*20, load_file=None)\n",
    "    mnist_rbm.train_model(-1, n_epoch=100, batch_size=10)\n",
    "    mnist_rbm.show_features()\n",
    "    mnist_rbm.test_reconstruct(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" and '__file__' not in globals():\n",
    "    model_file = \"mnist_rbm.784x140.epochs100\"\n",
    "    mnist_rbm = MNIST_RBM(None,None,model_file)\n",
    "    mnist_rbm.show_features()\n",
    "    mnist_rbm.test_reconstruct(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
